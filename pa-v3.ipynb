{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xJLK51NuRV9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c0d0d2-9193-4035-ba09-9c2fbb8c0328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/results\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "%mkdir results\n",
        "%cd /content/results\n",
        "%mkdir first_train\n",
        "%mkdir second_train\n",
        "%mkdir whole_train\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataloader.py\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class ClassFilter(Dataset):\n",
        "    def __init__(self, examples, filter_function):\n",
        "        self.data = [item for item in examples if filter_function(item[1])]\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.data[item]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "def makeLoader(pos: str, train: bool, filter_function):\n",
        "    return DataLoader(ClassFilter(CIFAR100(pos, train=train, transform=ToTensor(), download=True), filter_function), batch_size=64, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2AFDAjPRiXI",
        "outputId": "36ff2eb5-3726-44a6-9ade-0315c736c335"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataloader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile palib.py\n",
        "import torch\n",
        "from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Module, Sequential, BatchNorm2d, ReLU\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def extend_tensor(in_tensor: torch.Tensor, in_size: list, out_size: list):\n",
        "    if list(in_tensor.shape) != in_size:\n",
        "        raise ValueError(\"in_tensor and in_size mismatch\")\n",
        "    if len(in_size) != len(out_size):\n",
        "        raise ValueError(f\"cannot extend tensor size of {in_size} to {out_size}\")\n",
        "    for i in range(len(in_size)):\n",
        "        if in_size[i] == out_size[i]:\n",
        "            continue\n",
        "        in_tensor = torch.cat((in_tensor, torch.zeros(*[(in_size[j] if j > i else out_size[j]) if i != j else out_size[i] - in_size[i] for j in range(len(in_size))]).to(device)), dim=i)\n",
        "    return in_tensor.clone().detach().requires_grad_(True)\n",
        "\n",
        "class PAConv2d(Conv2d):\n",
        "    def __rshift__(self, other):\n",
        "        with torch.no_grad():\n",
        "            other.weight.copy_(extend_tensor(self.weight, list(self.weight.shape), list(other.weight.shape)))\n",
        "            other.bias.copy_(extend_tensor(self.bias, list(self.bias.shape), list(other.bias.shape)))\n",
        "\n",
        "\n",
        "class PALinear(Linear):\n",
        "    def __rshift__(self, other):\n",
        "        with torch.no_grad():\n",
        "            other.weight.copy_(extend_tensor(self.weight, list(self.weight.shape), list(other.weight.shape)))\n",
        "            other.bias.copy_(extend_tensor(self.bias, list(self.bias.shape), list(other.bias.shape)))\n",
        "\n",
        "class PAResBlock(Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size):\n",
        "        super(PAResBlock, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = 1\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.layers = Sequential(\n",
        "            PAConv2d(self.in_channels, self.out_channels, kernel_size=self.kernel_size, stride=self.stride, padding=1),\n",
        "            BatchNorm2d(num_features=self.out_channels),\n",
        "            ReLU(),\n",
        "            PAConv2d(self.out_channels, self.out_channels, kernel_size=self.kernel_size, stride=self.stride, padding=1),\n",
        "            BatchNorm2d(num_features=self.out_channels),\n",
        "        )\n",
        "        self.relu = ReLU()\n",
        "        if self.in_channels != self.out_channels:\n",
        "            self.shortcut = Sequential(\n",
        "                Conv2d(self.in_channels, self.out_channels, kernel_size=1, stride=self.stride, bias=False),\n",
        "                BatchNorm2d(num_features=self.out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.in_channels != self.out_channels:\n",
        "            return self.relu(self.shortcut(x) + self.layers(x))\n",
        "        return self.relu(x + self.layers(x))\n",
        "\n",
        "    def __rshift__(self, other):\n",
        "        self.layers[0] >> other.layers[0]\n",
        "        self.layers[3] >> other.layers[3]\n",
        "\n",
        "def formResBlocks(in_channels, out_channels, nums):\n",
        "    first_layer = PAResBlock(in_channels, out_channels, 3)\n",
        "    other_layers = [PAResBlock(out_channels, out_channels, 3) for _ in range(nums-1)]\n",
        "    return [first_layer, *other_layers]\n",
        "\n",
        "def formLinears(linear):\n",
        "    li = []\n",
        "    for i, o in zip(linear[:-1], linear[1:]):\n",
        "        li.append(PALinear(i, o))\n",
        "        li.append(ReLU())\n",
        "    return li[:-1]\n",
        "\n",
        "class PAResNet(Module):\n",
        "    def __init__(self, layer_nums: list, layer_channels: list, linear: list):\n",
        "        super().__init__()\n",
        "        if len(layer_nums) != len(layer_channels):\n",
        "            raise ValueError(\"unexpected layer_nums and layer_channels size\")\n",
        "\n",
        "        li = []\n",
        "        li.extend(formResBlocks(3, layer_channels[0], layer_nums[0]))\n",
        "        for i in range(len(layer_nums)-1):\n",
        "            li.append(MaxPool2d(2, 2))\n",
        "            li.extend(formResBlocks(layer_channels[i], layer_channels[i+1], layer_nums[1]))\n",
        "\n",
        "        self.blocks = Sequential(*li)\n",
        "        self.linear = Sequential(Flatten(), *formLinears([layer_channels[-1]*(32 >> (len(layer_nums)-1))*(32 >> (len(layer_nums)-1))]+linear))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(self.blocks(x))\n",
        "\n",
        "    def __rshift__(self, other):\n",
        "        for i in range(len(self.blocks)):\n",
        "            if isinstance(self.blocks[i], PAResBlock):\n",
        "                self.blocks[i] >> other.blocks[i]\n",
        "\n",
        "        for i in range(len(self.linear)):\n",
        "            if isinstance(self.linear[i], PALinear):\n",
        "                self.linear[i] >> other.linear[i]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1l4wnfhRrEY",
        "outputId": "f2087684-012f-4c45-f68b-df6b13bd7c74"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing palib.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import librarys\n",
        "from dataloader import makeLoader\n",
        "from palib import PAResNet\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import time"
      ],
      "metadata": {
        "id": "9UCGtHL5TiHs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "h-khXvRmTlsX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load datas\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "first_train_loader = makeLoader(r\"\\data\", True, lambda x: x < 75)\n",
        "first_test_loader = makeLoader(r\"\\data\", False, lambda x: x < 75)\n",
        "second_test_loader = makeLoader(r\"\\data\", False, lambda x: x >= 75)\n",
        "train_loader = makeLoader(r\"\\data\", True, lambda x: True)\n",
        "test_loader = makeLoader(r\"\\data\", False, lambda x: True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC32oR5TTqoK",
        "outputId": "1d48bf84-fdd7-4051-ff5c-cee9dbf59eac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to \\data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:12<00:00, 13175348.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting \\data/cifar-100-python.tar.gz to \\data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define loss function\n",
        "loss_fn = CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "-iE2BWwmTuA1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define other useful functions\n",
        "def calc_loss_and_accuracy(output, labels):\n",
        "    loss = loss_fn(output, labels)\n",
        "    _, pred = torch.max(output, 1)\n",
        "    return loss, torch.sum((pred == labels).squeeze()), torch.numel(pred)\n",
        "\n",
        "def test_(model, loader):\n",
        "    ss, cnt, ls = 0, 0, 0.0\n",
        "    model.eval()\n",
        "    for batch in tqdm(loader, unit=\"batch\", total=len(loader)):\n",
        "        inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "        output = model(inputs)\n",
        "        loss, acc, cor = calc_loss_and_accuracy(output, labels)\n",
        "        ss += acc.item()\n",
        "        cnt += cor\n",
        "        ls += loss.item() * cor\n",
        "    return ss, cnt, ls"
      ],
      "metadata": {
        "id": "FD9ymuqfTz8P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training and testing: pa\n",
        "st_time = time.time()\n",
        "\n",
        "train_loss_pa = []\n",
        "train_acc_pa = []\n",
        "train_t_pa = []\n",
        "train_acc_t_pa = []\n",
        "test_loss_pa = []\n",
        "test_acc_pa = []\n",
        "test_t_pa = []\n",
        "test_acc_t_pa = []\n",
        "test_acc_sub_pa = []\n",
        "\n",
        "model = PAResNet([2, 2, 2], [48, 96, 192], [384, 192, 75]).to(device)\n",
        "print(list(map(lambda x: x.size(), model.parameters())))\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(40):\n",
        "    ss, cnt = 0, 0\n",
        "    print(epoch)\n",
        "    model.train()\n",
        "    for batch in tqdm(first_train_loader, unit=\"batch\", total=len(first_train_loader)):\n",
        "        inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        loss, acc, cor = calc_loss_and_accuracy(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        ss += acc.item()\n",
        "        cnt += cor\n",
        "        train_loss_pa.append(loss.item())\n",
        "        train_t_pa.append(time.time() - st_time)\n",
        "    train_acc_pa.append(ss / cnt * 100)\n",
        "    train_acc_t_pa.append(time.time() - st_time)\n",
        "\n",
        "    ss, cnt, ls = test_(model, first_test_loader)\n",
        "    test_loss_pa.append(ls / cnt)\n",
        "    test_t_pa.append(time.time() - st_time)\n",
        "    test_acc_pa.append(ss / cnt * 100)\n",
        "    test_acc_t_pa.append(time.time() - st_time)\n",
        "    test_acc_sub_pa.append(0)\n",
        "    torch.save(model.state_dict(), f\"./results/first_train/params{epoch}.pt\")\n",
        "\n",
        "new_model = PAResNet([2, 2, 2], [64, 128, 256], [512, 256, 100]).to(device)\n",
        "print(list(map(lambda x: x.size(), new_model.parameters())))\n",
        "model >> new_model\n",
        "del model\n",
        "model = new_model\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(40, 60):\n",
        "    ss, cnt = 0, 0\n",
        "    print(epoch)\n",
        "    model.train()\n",
        "    for batch in tqdm(train_loader, unit=\"batch\", total=len(train_loader)):\n",
        "        inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        loss, acc, cor = calc_loss_and_accuracy(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        ss += acc.item()\n",
        "        cnt += cor\n",
        "        train_loss_pa.append(loss.item())\n",
        "        train_t_pa.append(time.time() - st_time)\n",
        "    train_acc_pa.append(ss / cnt * 100)\n",
        "    train_acc_t_pa.append(time.time() - st_time)\n",
        "\n",
        "    ss, cnt, ls = test_(model, test_loader)\n",
        "    test_loss_pa.append(ls / cnt)\n",
        "    test_t_pa.append(time.time() - st_time)\n",
        "    test_acc_pa.append(ss / cnt * 100)\n",
        "    test_acc_t_pa.append(time.time() - st_time)\n",
        "\n",
        "    ss, cnt, ls = test_(model, second_test_loader)\n",
        "    test_acc_sub_pa.append(ss / cnt * 100)\n",
        "    torch.save(model.state_dict(), f\"./results/second_train/params{epoch}.pt\")\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(train_t_pa, train_loss_pa, label='train loss: PA')\n",
        "plt.plot(test_t_pa, test_loss_pa, label='test loss: PA')\n",
        "plt.figure(2)\n",
        "plt.plot(train_acc_t_pa, train_acc_pa, label='train accuracy: PA')\n",
        "plt.plot(test_acc_t_pa, test_acc_pa, label='test accuracy: PA')\n",
        "plt.plot(test_acc_t_pa, test_acc_sub_pa, label='later 25 class test accuracy: PA')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "dsIBzvn4T8Ve",
        "outputId": "237d3f5d-0aad-487e-bff3-2c5edc1c8b86"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.Size([48, 3, 3, 3]), torch.Size([48]), torch.Size([48]), torch.Size([48]), torch.Size([48, 48, 3, 3]), torch.Size([48]), torch.Size([48]), torch.Size([48]), torch.Size([48, 3, 1, 1]), torch.Size([48]), torch.Size([48]), torch.Size([48, 48, 3, 3]), torch.Size([48]), torch.Size([48]), torch.Size([48]), torch.Size([48, 48, 3, 3]), torch.Size([48]), torch.Size([48]), torch.Size([48]), torch.Size([96, 48, 3, 3]), torch.Size([96]), torch.Size([96]), torch.Size([96]), torch.Size([96, 96, 3, 3]), torch.Size([96]), torch.Size([96]), torch.Size([96]), torch.Size([96, 48, 1, 1]), torch.Size([96]), torch.Size([96]), torch.Size([96, 96, 3, 3]), torch.Size([96]), torch.Size([96]), torch.Size([96]), torch.Size([96, 96, 3, 3]), torch.Size([96]), torch.Size([96]), torch.Size([96]), torch.Size([192, 96, 3, 3]), torch.Size([192]), torch.Size([192]), torch.Size([192]), torch.Size([192, 192, 3, 3]), torch.Size([192]), torch.Size([192]), torch.Size([192]), torch.Size([192, 96, 1, 1]), torch.Size([192]), torch.Size([192]), torch.Size([192, 192, 3, 3]), torch.Size([192]), torch.Size([192]), torch.Size([192]), torch.Size([192, 192, 3, 3]), torch.Size([192]), torch.Size([192]), torch.Size([192]), torch.Size([384, 12288]), torch.Size([384]), torch.Size([192, 384]), torch.Size([192]), torch.Size([75, 192]), torch.Size([75])]\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 586/586 [00:22<00:00, 25.55batch/s]\n",
            "100%|██████████| 118/118 [00:01<00:00, 101.98batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 199/586 [00:07<00:13, 28.09batch/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-90f0f99decff>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtrain_loss_pa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training and testing: cnn\n",
        "model = PAResNet([2, 2, 2], [64, 128, 256], [512, 256, 100]).to(device)\n",
        "\n",
        "st_time = time.time()\n",
        "optimizer = Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "train_loss_cnn = []\n",
        "train_acc_cnn = []\n",
        "train_t_cnn = []\n",
        "train_acc_t_cnn = []\n",
        "test_loss_cnn = []\n",
        "test_acc_cnn = []\n",
        "test_t_cnn = []\n",
        "test_acc_t_cnn = []\n",
        "test_acc_sub_cnn = []\n",
        "\n",
        "for epoch in range(50):\n",
        "    ss, cnt = 0, 0\n",
        "    print(epoch)\n",
        "    model.train()\n",
        "    for batch in tqdm(train_loader, unit=\"batch\", total=len(train_loader)):\n",
        "        inputs, labels = batch[0].to(device), batch[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(inputs)\n",
        "        loss, acc, cor = calc_loss_and_accuracy(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        ss += acc.item()\n",
        "        cnt += cor\n",
        "        train_loss_cnn.append(loss.item())\n",
        "        train_t_cnn.append(time.time() - st_time)\n",
        "    train_acc_cnn.append(ss / cnt * 100)\n",
        "    train_acc_t_cnn.append(time.time() - st_time)\n",
        "\n",
        "    ss, cnt, ls = test_(model, test_loader)\n",
        "    test_loss_cnn.append(ls / cnt)\n",
        "    test_t_cnn.append(time.time() - st_time)\n",
        "    test_acc_cnn.append(ss / cnt * 100)\n",
        "    test_acc_t_cnn.append(time.time() - st_time)\n",
        "\n",
        "    ss, cnt, ls = test_(model, second_test_loader)\n",
        "    test_acc_sub_cnn.append(ss / cnt * 100)\n",
        "    torch.save(model.state_dict(), f\"./results/whole_train/params{epoch}.pt\")\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(train_t_cnn, train_loss_cnn, label='train loss: CNN')\n",
        "plt.plot(test_t_cnn, test_loss_cnn, label='test loss: CNN')\n",
        "plt.figure(2)\n",
        "plt.plot(train_acc_t_cnn, train_acc_cnn, label='train accuracy: CNN')\n",
        "plt.plot(test_acc_t_cnn, test_acc_cnn, label='test accuracy: CNN')\n",
        "plt.plot(test_acc_t_cnn, test_acc_sub_cnn, label='later 25 class test accuracy: CNN')"
      ],
      "metadata": {
        "id": "1uZGzWMhUFHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show graphs\n",
        "plt.figure(1)\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss / Test Loss')\n",
        "plt.legend()\n",
        "plt.figure(2)\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training Accuracy / Test Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u2Ig2JmMUP8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define classes\n",
        "names = [\"apple\", \"aquarium_fish\", \"baby\", \"bear\", \"beaver\", \"bed\", \"bee\",\n",
        "    \"beetle\", \"bicycle\", \"bottle\", \"bowl\", \"boy\", \"bridge\",\n",
        "    \"bus\",\n",
        "    \"butterfly\",\n",
        "    \"camel\",\n",
        "    \"can\",\n",
        "    \"castle\",\n",
        "    \"caterpillar\",\n",
        "    \"cattle\",\n",
        "    \"chair\",\n",
        "    \"chimpanzee\",\n",
        "    \"clock\",\n",
        "    \"cloud\",\n",
        "    \"cockroach\",\n",
        "    \"couch\",\n",
        "    \"crab\",\n",
        "    \"crocodile\",\n",
        "    \"cup\",\n",
        "    \"dinosaur\",\n",
        "    \"dolphin\",\n",
        "    \"elephant\",\n",
        "    \"flatfish\",\n",
        "    \"forest\",\n",
        "    \"fox\",\n",
        "    \"girl\",\n",
        "    \"hamster\",\n",
        "    \"house\",\n",
        "    \"kangaroo\",\n",
        "    \"keyboard\",\n",
        "    \"lamp\",\n",
        "    \"lawn_mower\",\n",
        "    \"leopard\",\n",
        "    \"lion\",\n",
        "    \"lizard\",\n",
        "    \"lobster\",\n",
        "    \"man\",\n",
        "    \"maple_tree\",\n",
        "    \"motorcycle\",\n",
        "    \"mountain\",\n",
        "    \"mouse\",\n",
        "    \"mushroom\",\n",
        "    \"oak_tree\",\n",
        "    \"orange\",\n",
        "    \"orchid\",\n",
        "    \"otter\",\n",
        "    \"palm_tree\",\n",
        "    \"pear\",\n",
        "    \"pickup_truck\",\n",
        "    \"pine_tree\",\n",
        "    \"plain\",\n",
        "    \"plate\",\n",
        "    \"poppy\",\n",
        "    \"porcupine\",\n",
        "    \"possum\",\n",
        "    \"rabbit\",\n",
        "    \"raccoon\",\n",
        "    \"ray\",\n",
        "    \"road\",\n",
        "    \"rocket\",\n",
        "    \"rose\",\n",
        "    \"sea\",\n",
        "    \"seal\",\n",
        "    \"shark\",\n",
        "    \"shrew\",\n",
        "    \"skunk\",\n",
        "    \"skyscraper\",\n",
        "    \"snail\",\n",
        "    \"snake\",\n",
        "    \"spider\",\n",
        "    \"squirrel\",\n",
        "    \"streetcar\",\n",
        "    \"sunflower\",\n",
        "    \"sweet_pepper\",\n",
        "    \"table\",\n",
        "    \"tank\",\n",
        "    \"telephone\",\n",
        "    \"television\",\n",
        "    \"tiger\",\n",
        "    \"tractor\",\n",
        "    \"train\",\n",
        "    \"trout\",\n",
        "    \"tulip\",\n",
        "    \"turtle\",\n",
        "    \"wardrobe\",\n",
        "    \"whale\",\n",
        "    \"willow_tree\",\n",
        "    \"wolf\",\n",
        "    \"woman\",\n",
        "    \"worm\"\n",
        "]"
      ],
      "metadata": {
        "id": "ExzK4kGeUtht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing model\n",
        "model = None #load model\n"
      ],
      "metadata": {
        "id": "GKFRL6ZKUgIg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}